{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProyectoFinal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mario-Carmona/ProyectoFinal-VC/blob/main/ProyectoFinal.ipynb)"
      ],
      "metadata": {
        "id": "mlk22Pcv8B7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyecto Final**"
      ],
      "metadata": {
        "id": "txyYpKgN5e0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Autores:**\n",
        "\n",
        "\n",
        "\n",
        "*   [Aparicio Martos, Francisco José](https://github.com/pacoapm)\n",
        "*   [Carmona Segovia, Mario](https://github.com/Mario-Carmona)\n",
        "\n"
      ],
      "metadata": {
        "id": "FADtX3BH8dZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Definición del problema y enfoque seguido**"
      ],
      "metadata": {
        "id": "z_yBFVLd-t44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El problema que hemos abarcado en esta práctica es la detección de nadadores en videos de competiciones deportivas en colaboración con la facultad de ciencias del deporte.\n",
        "\n",
        "  Se trata de un problema de detección de objetos, en este caso, personas. Es un problema distinto a los que hemos tratado hasta ahora ya que no se puede etiquetar como un problema de clasificación o regresión, si no que se trata de un problema que combina ambos aspectos: clasificación, ya que se tiene que detectar si un objeto está o no presente en una imagen y decir a que clase pertenece; y regresión, pues se tiene que rodear a dicho elemento en un Bounding Box. \n",
        "\n",
        "  Para poder enfocar este problema tenemos a usar una red neuronal convolucional orientada a detección de objetos. La elegida ha sido la red YOLO ya que se trata de una red que alcanza resultados muy buenos y además se puede ejecutar en tiempo real si se tiene el hardware necesario. \n",
        "\n",
        "  La red YOLO ha sido entrenada en la base de datos [COCO](https://cocodataset.org/#home) la cual está compuesta por 80 clases de objetos diferentes, siendo una de ellas la clase persona. Debido a que la red consigue reconocer personas podríamos pensar que la detección se podría hacer usando directamente la red, pero existe principalmente 2 problemas: \n",
        "\n",
        "1.  La orientación de las personas. Las personas que detecta yolo se encuentran en disposición vertical mientras que los nadadores en los videos nadan horizontalmente. \n",
        "2.  El agua, pues distorsiona la luz y por lo tanto la forma en la que se ven a los nadadores.\n",
        "\n",
        "El primero de los problemas se puede resolver de manera sencilla, pues lo único que hace falta es girar los videos para que de esta forma los nadadores aparezcan desplazandose en el eje vertical. Este experimento fue realizado por los estudiantes de la facultad de deportes consiguiendo resultados decentes aunque mejorables.\n",
        "\n",
        "Partiendo de la base que ya existe un modelo que consigue resultados decentes en nuestra base de datos y que estos se pueden mejorar, el enfoque que hemos seguido en la práctica es el conocido como fine tuning. Este proceso consiste en dado una red preentrenada en una base de datos distinta a la que se va a estudiar, realizar un entrenamiento corto (5-10-15 épocas) para de esta forma mover el óptimo de la red hacia el óptimo de nuestro problema. \n",
        " \n",
        "Las bondades de esta metodología son: ahorramos tiempo de entrenamiento, pues no tenemos que entrenar la red al completo lo cual tardaría días. Al haber sido preentrenada en una BBDD grande como COCO evitamos que haya overfitting y mejoramos su rendimiento, pues para que las cnn puedan generalizar correctamente necesitan entrenarse en una gran cantidad de datos.\n"
      ],
      "metadata": {
        "id": "WdMdUBhi-52b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fine tuning con YOLOv3**\n"
      ],
      "metadata": {
        "id": "BUUUaTQJXgPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como modelo base para hacer el primer fine tuning hemos usado el modelo YOLOv3 proporcionado en el repositorio de github del investigador Alexey Bochkovskiy https://github.com/AlexeyAB/darknet . \n",
        "\n",
        "Para poder realizar el entrenamiento hemos tenido que aplicar una serie de cambios especificados por el autor para que de esta forma la red se adecúe a nuestro problema.\n",
        "\n",
        "Lo primero que hemos realizado ha sido realizar un copia del archivo que almacena la arquitectura de la red ([darknet/cfg/yolov3.cfg](https://github.com/Mario-Carmona/ProyectoFinal-VC/blob/main/darknet/cfg/yolov3.cfg)). En este archivo hemos tenido que editar:\n",
        "* El tamaño del batch a 64. \n",
        "* Las subidivisiones las establecemos a 16 (número de mini batches en las que se divide el batch, para que se procesen en paralelo).\n",
        "* El número máximo de iteraciones la establecemos a 2000*número de clases, es decir, 2000.\n",
        "* El parámetro steps lo hemos establecido al 80% y 90% del total de iteraciones. Este parámetro indica las iteraciones en las que el learning rate va a ser multiplicado por el valor especificado en el parámetro scales.\n",
        "* Cambiamos la resolución de entrada de la red a 416x416, esta siempre tiene que ser múltiplo de 32.\n",
        "* Cambiamos el número de clases en cada una de las capas yolo. Como solo vamos a detectar nadadores este parámetro lo hemos fijado a 1.\n",
        "* Cambiamos la profundidad de los tensores resultantes de las capas convolucionales que van justo antes de las capas yolo a (numero de clases + 5) * 3. Esta profundidad tiene esta fórmula ya que en cada una de las celdas del tensor resultante se da información a cerca de los 3 BB que predice YOLO por cada una de las celdas en las que se divide la imagen, de ahí que se multiplique por 3. Por cada uno de estos bounding boxes se indica con 0 o 1 si hay o no un objeto presente en dicha celda, se dan las 4 coordenas (x esquina superior izquierda, y esquina superior izquierda, ancho y alto) que describen el bounding box, y por cada una de las clases un valor entre 0 y 1 indicando la probabilidad de que exista un objeto de dicha clase en la imagen.\n",
        "\n",
        "Tras haber modificado la red para poder aplicar fine tuning nos dispusimos a hacer la división de la base de datos en el conjunto de entrenamiento, validación y test. \n",
        "\n",
        "Para los cojuntos de entrenamiento y validación usamos la carpeta que se nos proporcionó llamada: [TrainingSET](https://github.com/Mario-Carmona/ProyectoFinal-VC/tree/main/BBDD_Nadadores/TrainingSET). De esta carpeta el 80% se destinó a entrenamiento y el otro 20% a validación. El objetivo de crear la carpeta de validación es poder usarla para evaluar nuestro modelo y usarlo para poder comparar con las distintas versiones que creemos.\n",
        "\n",
        "Con respecto al conjunto de test usamos las imagenes que venían en la carpeta [crops_120x120](https://github.com/Mario-Carmona/ProyectoFinal-VC/tree/main/BBDD_Nadadores/crops_120x120).\n",
        "\n",
        "Todas estas divisiones se han realizado mediante la creación de los respectivos archivos train.txt y valid.txt que se le pasará a la red. En cada uno de los archivos se indica que imágenes se destinan a training y a validación.\n",
        "\n",
        "Con la red y la base de datos ya preparada ahora ya solo nos queda ejecutar la red y esperar a ver que resultados ofrece."
      ],
      "metadata": {
        "id": "ia5b5kwEXw_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSERTAR RESULTADOS**"
      ],
      "metadata": {
        "id": "_oTGPzplmkEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obtener las métricas de la red hemos creado una función en el código en C que usando el conjunto de validación evalúa el modelo y mide la precisión, el recall, el F1-score y el average intersection over union.\n",
        "\n",
        "Con el objetivo de poder valorar correctamente el modelo me dispongo a explicar cada una de las métricas que usaremos para la comparación:\n",
        "\n",
        "* Precision: porcentaje de los casos clasificados como positivos que realmente son positivos. Es decir, $\\frac{TP}{TP+FP}$.\n",
        "* Recall: porcentaje de los casos que son positivos y que se han clasificado como tal. Es decir, $\\frac{TP}{TP+FN}$\n",
        "* F1-score: es una media armónica de las anteriores medidas.\n",
        "* Average intersection over union: es la media de los intersection over union de cada detección. Intersection over union se trata de una medida que indica el nivel de solapamiento que hay entre el BB predecido y el BB verdadero, siendo 1 que ambos coinciden perfectamente y 0 si estos no coinciden. La forma de calcula dicho cociente es la siguiente: $\\frac{interseccion\\_BBs}{union\\_BBs}$.\n"
      ],
      "metadata": {
        "id": "UtGX2jurnQWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSERTAR VALORACION DEL MODELO**"
      ],
      "metadata": {
        "id": "WEOfjy_YwtVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Procesado de video con YOLOv3**"
      ],
      "metadata": {
        "id": "nEoZyVt031R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez sabemos que el modelo ha obtenido muy buenos valores tanto en f1-score como en avg-iou nos disponemos a usarlo en los videos de la base de datos.   \n",
        "\n",
        "Procesamos el video con la red YOLO y nos llevamos la sorpresa de que no detecta a los nadadores, a pesar de las métricas tan buenas que se habían obtenido.  Al no cuadrarnos estos resultados decidimos investigar cuales son los motivos por los que no se hace la detección y encontramos que uno de los posibles problemas es el tamaño de los nadadores en los videos. Si vemos los videos, los nadadores ocupan un pequeño porcentaje y esto genera problemas para la red YOLO. Bajo esta suposición insertamos unas modificaciones que recomienda el autor para cuando el objetivo es detectar objetos pequeños. \n",
        "\n",
        "Dichos cambios son:\n",
        "* cambiar la capa route que se encuentra en la linea 720 a -1,11. Esta capa indica los tensores de las capas se van a usar para juntarlos con el tensor actual.\n",
        "* cambiar el stride de la capa upsample de la linea 717 a 4.\n",
        "\n",
        "Tras realizar el fine tuning volvimos a realizar la detección en video pero esta vez, además de los cambios introducidos en la red durante el fine tuning, aumentamos el tamaño de las imagenes de entrada de la red, y ahora sí, el modelo era capaz de detectar a los nadadores en el vídeo. Probamos varios tamaños de entrada para encontrar un equilibrio entre calidad de detección y velocidad para ver si era posible ejecutarlo en tiempo real. Tras varios experimentos concluimos que el equipo proporcionado por colab no es lo suficientemente potente como para poder procesar dicho modelo en tiempo real. \n",
        "\n",
        "Al hacer varias detecciones en los videos nos dimos cuenta de que aparecía otro problema en la red, y es que cuando los nadadores llegaban al final de la piscina y se daban la vuelta el modelo dejaba de detectarlos ya que la habíamos entrenado solamente para cuando estos estaban derechos. Es por ello, que decidimos hacer un aumento de datos introduciendo en el training las imagenes que ya existían con un flip, y de igualforma en la validación. \n",
        "\n",
        "Modificado el training set hicimos el fine tuning y volvimos a realizar la detección en video, y ahora sí, el modelo ya puede detectar a los nadadores independientemente de la fase de la carrera en la que se encuentren.\n",
        "\n"
      ],
      "metadata": {
        "id": "2upTHGmiww9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports:**"
      ],
      "metadata": {
        "id": "neNUBvXx_m_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from moviepy.editor import VideoFileClip\n",
        "import random\n",
        "random.seed(0)\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "id": "c236RzEa_yPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Código:**"
      ],
      "metadata": {
        "id": "gTq2z67L9Yr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Funciones**</u>"
      ],
      "metadata": {
        "id": "EmV9zJsggqWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones auxiliares**"
      ],
      "metadata": {
        "id": "qJjTkEcBhkD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define helper functions\n",
        "def imShow(path: str)->'void':\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload()->'void':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path: str)->'void':\n",
        "  from google.colab import files\n",
        "  files.download(path)\n",
        "\n",
        "# use this to download a file in Drive \n",
        "def downloadDrive(source: str, desti: str)->'void':\n",
        "  shutil.copy(source, desti)\n"
      ],
      "metadata": {
        "id": "6jEQM-RShqlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para generación del entorno de trabajo**"
      ],
      "metadata": {
        "id": "7E9qx4QGgsCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Generar carpetas en Drive**"
      ],
      "metadata": {
        "id": "Q5D3GZ2kg13v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Función para la generación del directorio principal y de la carpeta de pesos dentro del Drive\n",
        "\n",
        "- path: Ruta de la carpeta principal\n",
        "\"\"\"\n",
        "def generarDirectorioPrin(path: str)->'void':\n",
        "  # Se comprueba la existencia del directorio\n",
        "  existe = os.path.isdir(path)\n",
        "  # si no existe se crea la estructura de la carpeta principal\n",
        "  if(not existe):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path + \"/Weight\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para la generación de carpetas dentro del Drive\n",
        "\n",
        "- path: Ruta de la carpeta\n",
        "\"\"\"\n",
        "def generarDirectorio(path: str)->'void':\n",
        "  # Se comprueba la existencia del directorio\n",
        "  existe = os.path.isdir(path)\n",
        "  # Si existe se procede a borrar el directorio\n",
        "  # Exista o no se vuelve a crear el directorio\n",
        "  if(existe):\n",
        "    shutil.rmtree(path)\n",
        "    os.mkdir(path)\n",
        "  else:\n",
        "    os.mkdir(path)\n"
      ],
      "metadata": {
        "id": "0ZP91c2ag7ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Generar Dataset**"
      ],
      "metadata": {
        "id": "_hAawXWBjyc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Función para dividir el dataset en conjunto de training y conjunto de validación\n",
        "\n",
        "- rutaDataset: Ruta del directorio que contiene el dataset\n",
        "- nombreCarpeTrain: Nombre de la carpeta que contendrá el conjunto de training\n",
        "- nombreCarpeValid: nombre de la carpeta que contendrá el conjunto de validación\n",
        "- rutaSalida: Ruta de la carpeta que contendrá las carpetas con los conjuntos de datos\n",
        "- porcenVali: Porcentaje de las imágenes que formarán parte del conjunto de validación\n",
        "\"\"\"\n",
        "def dividirDataset(rutaDataset: str, nombreCarpeTrain: str, nombreCarpeValid: str, \n",
        "                   rutaSalida: str, porcenVali:float)->(str, str):\n",
        "    # Se obtienen todas las imágenes del dataset\n",
        "    imagenes = sorted(glob.glob(rutaDataset + \"*.jpg\"))\n",
        "\n",
        "    # Se calcula el número de imágenes en cada conjunto de datos\n",
        "    numImgTrain = len(imagenes)\n",
        "    numImgTest = int(numImgTrain * porcenVali)\n",
        "\n",
        "    # Creación de las ruta de las carpetas para los conjuntos de datos\n",
        "    carpetaTrain = rutaSalida + nombreCarpeTrain\n",
        "    carpetaTest = rutaSalida + nombreCarpeValid\n",
        "\n",
        "    # Creación de la carpeta de training\n",
        "    try:\n",
        "        os.mkdir(carpetaTrain)\n",
        "    except FileExistsError:\n",
        "        shutil.rmtree(carpetaTrain)\n",
        "        os.mkdir(carpetaTrain)\n",
        "      \n",
        "    # Creación de la carpeta de validación\n",
        "    try:\n",
        "        os.mkdir(carpetaTest)\n",
        "    except FileExistsError:\n",
        "        shutil.rmtree(carpetaTest)\n",
        "        os.mkdir(carpetaTest)\n",
        "\n",
        "    # Creación del conjunto de validación\n",
        "    validation = []\n",
        "\n",
        "    for i in range(numImgTest):\n",
        "        img = random.choice(imagenes)\n",
        "        validation.append(img)\n",
        "        imagenes.remove(img)\n",
        "\n",
        "    # Creación del conjunto de training\n",
        "    train = imagenes\n",
        "\n",
        "    # Copia de las imágenes y sus BB a la carpeta de training\n",
        "    for img in train:\n",
        "        shutil.copy(img, carpetaTrain)\n",
        "        nombreImg = img.split('.')[0]\n",
        "        shutil.copy(nombreImg + \".txt\", carpetaTrain)\n",
        "\n",
        "    # Copia de las imágenes y sus BB a la carpeta de validación\n",
        "    for img in validation:\n",
        "        shutil.copy(img, carpetaTest)\n",
        "        nombreImg = img.split('.')[0]\n",
        "        shutil.copy(nombreImg + \".txt\", carpetaTest)\n",
        "\n",
        "    return carpetaTrain, carpetaTest\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para aumentar el conjunto de datos realizando el flip vertical de todas las imágenes\n",
        "del conjunto de datos.\n",
        "\n",
        "- carpeta: Ruta de la carpeta que contiene el conjunto de datos\n",
        "\"\"\"\n",
        "def generarFlip(carpeta: str)->'void':\n",
        "    # Obtenemos las imágenes del conjunto de datos\n",
        "    imagenes = sorted(glob.glob(carpeta + \"/*.jpg\"))\n",
        "\n",
        "    # Para cada imagenes del conjunto de datos\n",
        "    for img in imagenes:\n",
        "        # Se obtiene el nombre junto con su ruta\n",
        "        nombreImg = img.split('.')[0]\n",
        "\n",
        "        # Se realiza el flip vertical de la imagen\n",
        "        imagen = cv2.imread(nombreImg + \".jpg\")\n",
        "        imagen_flip = cv2.flip(imagen, 0)\n",
        "        # Se genera la imagen con flip modificando el nombre original de la imagen\n",
        "        cv2.imwrite(nombreImg + \"_flip.jpg\", imagen_flip)\n",
        "        \n",
        "        # Leemos el BB de la imagen original\n",
        "        with open(nombreImg + \".txt\", \"r\") as f:\n",
        "          contenido = f.read()\n",
        "\n",
        "        # Modificamos la coordenada y del centro del BB\n",
        "        partes = contenido.split(' ')\n",
        "        partes[2] = \"{:.6f}\".format(round(1.0-float(partes[2]), 6))\n",
        "\n",
        "        # Generamos el BB de la imagen con flip\n",
        "        with open(nombreImg + \"_flip.txt\", \"w+\") as f:\n",
        "          for i in partes[:-1]:\n",
        "            f.write(i + \" \")\n",
        "          f.write(partes[-1])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para generar el archivo resumen del training a partir del conjunto de training\n",
        "\n",
        "- carpetaTrain: Ruta de la carpeta que contiene el conjunto de training\n",
        "- archivoTrain: Nombre del archivo resumen del training\n",
        "\"\"\"\n",
        "def generarTrain(carpetaTrain: str, archivoTrain: str)->str:\n",
        "    # Lista que contendrá el nombre de las imágenes de training\n",
        "    image_files = []\n",
        "    # Obtenemos la ruta actual\n",
        "    cwdIni = os.getcwd()\n",
        "\n",
        "    # Nos movemos a la carpeta de training\n",
        "    os.chdir(carpetaTrain)\n",
        "\n",
        "    # Para cada imagen de training\n",
        "    for filename in os.listdir(os.getcwd()):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            # Añado la ruta de la imagen a la lista\n",
        "            image_files.append(carpetaTrain + \"/\" + filename)\n",
        "\n",
        "    # Nos movemos a la carpeta anterior\n",
        "    os.chdir(\"..\")\n",
        "\n",
        "    # Generamos el resumen de training\n",
        "    with open(archivoTrain, \"w+\") as outfile:\n",
        "        for image in image_files:\n",
        "            outfile.write(image)\n",
        "            outfile.write(\"\\n\")\n",
        "    \n",
        "    # Nos movemos a la ruta que se guardó al principio de la función\n",
        "    os.chdir(cwdIni)\n",
        "\n",
        "    return archivoTrain\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para generar el archivo resumen de la validación a partir del conjunto de validación\n",
        "\n",
        "- carpetaTest: Ruta de la carpeta que contiene el conjunto de validación\n",
        "- archivoValid: Nombre del archivo resumen de la validación\n",
        "\"\"\"\n",
        "def generarValid(carpetaTest: str, archivoValid: str)->str:\n",
        "    # Lista que contendrá el nombre de las imágenes de la validación\n",
        "    image_files = []\n",
        "    # Obtenemos la ruta actual\n",
        "    cwdIni = os.getcwd()\n",
        "\n",
        "    # Nos movemos a la carpeta de validación\n",
        "    os.chdir(carpetaTest)\n",
        "\n",
        "    # Para cada imagen de validación\n",
        "    for filename in os.listdir(os.getcwd()):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            # Añado la ruta de la imagen a la lista\n",
        "            image_files.append(carpetaTest + \"/\" + filename)\n",
        "\n",
        "    # Nos movemos a la carpeta anterior\n",
        "    os.chdir(\"..\")\n",
        "\n",
        "    # Generamos el resumen de validación\n",
        "    with open(archivoValid, \"w+\") as outfile:\n",
        "        for image in image_files:\n",
        "            outfile.write(image)\n",
        "            outfile.write(\"\\n\")\n",
        "\n",
        "    # Nos movemos a la ruta que se guardó al principio de la función\n",
        "    os.chdir(cwdIni)\n",
        "\n",
        "    return archivoValid\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para obtener la lista y el número de clases que contiene el dataset\n",
        "\n",
        "- rutaDataset: Ruta de la carpeta que contiene el dataset\n",
        "- archivoClases: Nombre del archivo que contiene las distintas clases del dataset\n",
        "\"\"\"\n",
        "def obtenerClases(rutaDataset: str, archivoClases: str)->(str, int):\n",
        "    # Obtenemos todas las clases del dataset\n",
        "    with open(rutaDataset + archivoClases, \"r\") as file:\n",
        "        contenido = file.read()\n",
        "\n",
        "    # Calculamos el número de clases del dataset\n",
        "    listaClases = contenido.split('\\n')\n",
        "    numClases = len(listaClases) - 1\n",
        "\n",
        "    return contenido, numClases\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para generar el archivo .names del conjunto de datos\n",
        "\n",
        "- rutaSalida: Ruta de la carpeta que contiene el conjunto de datos\n",
        "- nombreCarpeTrain: Nombre de la carpeta que contiene el conjunto de training\n",
        "- clases: Lista de clases que contiene el conjunto de datos\n",
        "\"\"\"\n",
        "def generarNames(rutaSalida: str, nombreCarpeTrain: str, clases: str)->str:\n",
        "    # Se obtiene el nombre del archivo a generar\n",
        "    archivoNames = nombreCarpeTrain + \".names\"\n",
        "\n",
        "    # Se genera el archivo .names, junto con su contenido\n",
        "    with open(rutaSalida + archivoNames, \"w+\") as outfile:\n",
        "        outfile.write(clases)\n",
        "\n",
        "    return archivoNames\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para generar el archivo .data del conjunto de datos\n",
        "\n",
        "- rutaSalida: Ruta de la carpeta que contiene el conjunto de datos\n",
        "- nombreCarpeTrain: Nombre de la carpeta que contiene el conjunto de training\n",
        "- numClases: Número de clases del conjunto de datos\n",
        "- archivoTrain: Nombre del archivo resumen del conjunto de training\n",
        "- archivoValid: Nombre del archivo resumen del conjunto de validación\n",
        "- archivoNames: Nombre del archivo .names del conjunto de datos\n",
        "- carpetaBackup: Ruta de la carpeta que guardará los pesos durante el entrenamiento\n",
        "\"\"\"\n",
        "def generarData(rutaSalida: str, nombreCarpeTrain: str, numClases: int, archivoTrain: str, \n",
        "                archivoValid: str, archivoNames: str, carpetaBackup: str)->'void':\n",
        "    # Se obtiene el nombre del archivo a generar\n",
        "    archivoData = nombreCarpeTrain + \".data\"\n",
        "\n",
        "    # Se genera el archivo .names, junto con su contenido\n",
        "    with open(rutaSalida + archivoData, \"w+\") as outfile:\n",
        "        outfile.write(\"classes = \" + str(numClases) + \"\\n\")\n",
        "        outfile.write(\"train = \" + rutaSalida + archivoTrain + \"\\n\")\n",
        "        outfile.write(\"valid = \" + rutaSalida + archivoValid + \"\\n\")\n",
        "        outfile.write(\"names = \" + rutaSalida + archivoNames + \"\\n\")\n",
        "        outfile.write(\"backup = \" + carpetaBackup)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para genera el conjunto de datos para el fine tuning\n",
        "\n",
        "- rutaDataset: Ruta de la carpeta que contiene el dataset\n",
        "- rutaSalida: Ruta de la carpeta que contiene el conjunto de datos\n",
        "- porcenVali: Porcentaje de las imágenes que formarán parte del conjunto de validación\n",
        "\"\"\"\n",
        "def generarDataset(rutaDataset: str, rutaSalida: str, porcenVali: float)->'void':\n",
        "    nombreCarpeTrain = \"obj\"\n",
        "    nombreCarpeValid = \"valid\"\n",
        "\n",
        "    archivoTrain = \"train.txt\"\n",
        "    archivoValid = \"valid.txt\"\n",
        "\n",
        "    archivoClases = \"classes.txt\"\n",
        "\n",
        "    carpetaBackup = \"mydrive/ProyectoFinal/Weight\"\n",
        "\n",
        "    carpetaTrain, carpetaTest = dividirDataset(rutaDataset, nombreCarpeTrain, nombreCarpeValid, rutaSalida, porcenVali)\n",
        "\n",
        "    #generarFlip(carpetaTrain)\n",
        "\n",
        "    #generarFlip(carpetaTest)\n",
        "\n",
        "    generarTrain(carpetaTrain, archivoTrain)\n",
        "\n",
        "    generarValid(carpetaTest, archivoValid)\n",
        "\n",
        "    clases, numClases = obtenerClases(rutaDataset, archivoClases)\n",
        "\n",
        "    archivoNames = generarNames(rutaSalida, nombreCarpeTrain, clases)\n",
        "\n",
        "    generarData(rutaSalida, nombreCarpeTrain, numClases, archivoTrain, archivoValid, archivoNames, carpetaBackup)\n"
      ],
      "metadata": {
        "id": "3v8kj8NBj2WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones gráficas**"
      ],
      "metadata": {
        "id": "HaADVuJviOe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#funcion que mide el recall, la precision y el f1 de nuestro modelo\n",
        "def evaluacionModelo(pesos, archivo_modelo, archivo_resultados, iter_ini = 0, iter_fin = 2050):\n",
        "  #limpiamos el fichero de datos\n",
        "  os.system(r\"echo \"\" > /content/gdrive/My\\ Drive/ProyectoFinal/DatosGrafica/\"+ archivo_resultados)\n",
        "  modeloTest = generarModeloTest(archivo_modelo)\n",
        "  #evaluamos el modelo en cada una de las evaluaciones\n",
        "  for i in range(iter_ini,iter_fin,50):\n",
        "    print(\"./darknet detector recprec data/obj.data \" + modeloTest + \" \"+ pesos + str(i) + r\".weights >> /content/gdrive/My\\ Drive/ProyectoFinal/DatosGrafica/\"+archivo_resultados)\n",
        "    os.system(r\"./darknet detector recprec data/obj.data \" + modeloTest + \" \"+ pesos + str(i) + r\".weights >> /content/gdrive/My\\ Drive/ProyectoFinal/DatosGrafica/\"+archivo_resultados)\n",
        "  \n",
        "def mostrarGrafica(medida,archivo,iter_ini,iter_fin):\n",
        "  f = open(\"/content/gdrive/My Drive/ProyectoFinal/DatosGrafica/\"+archivo, \"r\")\n",
        "  comment = f.read()\n",
        "  valores = re.findall(medida + ' = ([0-9]*.[0-9]*)',comment)\n",
        "  valores = [float(i) for i in valores]\n",
        "  x = range(iter_ini,iter_fin,50)\n",
        "  #buscamos el valor maximo\n",
        "  vmax = max(valores)\n",
        "  indice_max = valores.index(max(valores))\n",
        "\n",
        "  \n",
        "  plt.plot(x,valores)\n",
        "  plt.plot(x[indice_max],vmax, \"ro\")\n",
        "  plt.yscale(\"linear\")\n",
        "  plt.xlabel(\"iteration\")\n",
        "  plt.ylabel(medida)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"El \" + medida + \" maxima se alcanza en la iteracion \" + str(x[indice_max]) + \" valor: \" + str(vmax))\n",
        "\n",
        "pesosv3Base = \"mydrive/ProyectoFinal/Weight/ModeloBaseYOLOv3/yolov3-modeloBase_\"\n",
        "pesosv3 = \"mydrive/ProyectoFinal/Weight/FineTuningYOLOv3/yolov3-fineTuning_\"\n",
        "pesosv4 = \"mydrive/ProyectoFinal/Weight/FineTuningYOLOv4/yolov4-prueba_3_\"\n",
        "\n",
        "modelov3Base = \"cfg/yolov3-modeloBase.cfg\"\n",
        "modelov3 = \"cfg/yolov3-fineTuning.cfg\"\n",
        "modelov4 = \"cfg/yolov4-fineTuning.cfg\"\n",
        "\n"
      ],
      "metadata": {
        "id": "I7XZJ8MiiRYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluacionModelo(pesosv3Base,modelov3Base,\"Datosv3Base.txt\",400,2050)"
      ],
      "metadata": {
        "id": "mpBqzoLDL_hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para generación de modelos**"
      ],
      "metadata": {
        "id": "YPTmiAVv02fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Función para generar el modelo para test a partir de otro modelo\n",
        "\n",
        "- archivoModelo: Ruta del archivo modelo usado como base\n",
        "\"\"\"\n",
        "def generarModeloTest(archivoModelo: str)->str:\n",
        "  # Se obtiene la ruta del modelo sin el formato\n",
        "  archivo = archivoModelo.split('.')[0]\n",
        "  # Se genera la ruta del nuevo modelo\n",
        "  archivoModeloTest = archivo + \"-test.cfg\"\n",
        "\n",
        "  # Si no existe el nuevo modelo\n",
        "  if(not os.path.exists(archivoModeloTest)):\n",
        "    # Se hace una copia del modelo base\n",
        "    shutil.copy(archivoModelo, archivoModeloTest)\n",
        "    # Se modificar el valor del batch\n",
        "    os.system(r\"sed -i 's/batch=64/batch=1/' \" + archivoModeloTest)\n",
        "    # Se modificar el valor del subdivisions\n",
        "    os.system(r\"sed -i 's/subdivisions=16/subdivisions=1/' \" + archivoModeloTest)\n",
        "\n",
        "  return archivoModeloTest\n"
      ],
      "metadata": {
        "id": "dLXECo9X08Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para detección imágenes**"
      ],
      "metadata": {
        "id": "a6BmvqrlirSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Función para generar una lista de las imágenes contenidas en una carpeta\n",
        "\n",
        "- carpetaImagenes: Ruta de la carpeta que contiene las imágenes\n",
        "\"\"\"\n",
        "def obtenerImagenes(carpetaImagenes: str)->'void':\n",
        "  image_files = []\n",
        "\n",
        "  for filename in os.listdir(carpetaImagenes):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "      image_files.append(carpetaImagenes + \"/\" + filename)\n",
        "  \n",
        "  with open(\"images.txt\", \"w+\") as outfile:\n",
        "    for image in image_files:\n",
        "      outfile.write(image)\n",
        "      outfile.write(\"\\n\")\n",
        "\n",
        "\n",
        "def ejecutarDeteccion(archivoData, archivoModelo, archivoPesos, archivoJSON, umbralDetec):\n",
        "  cmd = \"./darknet detector test \" + archivoData + \" \" + archivoModelo + \" \" + archivoPesos + \" -thresh \" + str(umbralDetec) + \" -ext_output -dont_show -out \" + archivoJSON + \" < images.txt\"\n",
        "  os.system(cmd)\n",
        "\n",
        "  for filename in os.listdir(os.getcwd()):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "      shutil.move(filename, \"predictions\")\n",
        "\n",
        "\n",
        "def dividirPredictions(confidence, archivoJSON, carpeta):\n",
        "  carpetaDetectados = carpeta + \"/Detectados\"\n",
        "  carpetaNoDetectados = carpeta + \"/NoDetectados\"\n",
        "  carpetaOtros = carpeta + \"/Otros\"\n",
        "\n",
        "  generarDirectorio(carpeta)\n",
        "  generarDirectorio(carpetaDetectados)\n",
        "  generarDirectorio(carpetaNoDetectados)\n",
        "  generarDirectorio(carpetaOtros)\n",
        "\n",
        "  downloadDrive(archivoJSON, carpeta)\n",
        "\n",
        "  with open(archivoJSON, 'r', encoding=\"utf8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  numDetectados = 0\n",
        "  numNoDetectados = 0\n",
        "  numOtros = 0\n",
        "\n",
        "  imagenes = []\n",
        "  for imagen in data:\n",
        "    nombreImg = imagen['filename']\n",
        "    nombreImg = nombreImg.split(\"/\")[-1]\n",
        "\n",
        "    objetos = imagen['objects']\n",
        "\n",
        "    if(len(objetos) == 0):\n",
        "      shutil.move(\"predictions/\" + nombreImg, carpetaNoDetectados)\n",
        "      numNoDetectados += 1\n",
        "    else:\n",
        "      confianza = []\n",
        "      for i in range(len(objetos)):\n",
        "        confianza.append((i, objetos[i]['confidence']))\n",
        "\n",
        "      sorted(confianza, reverse=True, key=lambda confi : confi[1])\n",
        "\n",
        "      indiceObj = confianza[0][0]\n",
        "\n",
        "      if(objetos[indiceObj]['name'] == \"person\"):\n",
        "        if(objetos[indiceObj]['confidence'] >= confidence):\n",
        "          shutil.move(\"predictions/\" + nombreImg, carpetaDetectados)\n",
        "          numDetectados += 1\n",
        "        else:\n",
        "          shutil.move(\"predictions/\" + nombreImg, carpetaNoDetectados)\n",
        "          numNoDetectados += 1\n",
        "      else:\n",
        "        shutil.move(\"predictions/\" + nombreImg, carpetaOtros)\n",
        "        numOtros += 1\n",
        "\n",
        "  with open(carpeta + \"/resumenPrediccion.txt\", 'w+', encoding=\"utf8\") as f:\n",
        "    f.write(\"Detectados: \" + str(numDetectados) + \"\\n\")\n",
        "    f.write(\"No Detectados: \" + str(numNoDetectados) + \"\\n\")\n",
        "    f.write(\"Otros: \" + str(numOtros))\n",
        "\n",
        "  os.remove(archivoJSON)\n",
        "\n",
        "\n",
        "def realizarDeteccionImagenes(carpetaImagenes, archivoData, archivoModelo, archivoPesos, archivoJSON, umbralDetec, carpetaDrive, umbralPredic):\n",
        "  obtenerImagenes(carpetaImagenes)\n",
        "\n",
        "  archivoModeloTest = generarModeloTest(archivoModelo)\n",
        "\n",
        "  ejecutarDeteccion(archivoData, archivoModeloTest, archivoPesos, archivoJSON, umbralDetec)\n",
        "\n",
        "  dividirPredictions(umbralPredic, archivoJSON, carpetaDrive)\n",
        "\n",
        "\n",
        "def realizarDeteccionImagen(archivoImagen, archivoData, archivoModelo, archivoPesos, umbralDetec):\n",
        "  archivoModeloTest = generarModeloTest(archivoModelo)\n",
        "\n",
        "  os.system(\"./darknet detector test \" + archivoData + \" \" + archivoModeloTest + \" \" + archivoPesos + \" -thresh \" + str(umbralDetec) + \" -dont_show \" + archivoImagen)\n"
      ],
      "metadata": {
        "id": "H2wchQrRitxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para Fine Tuning**"
      ],
      "metadata": {
        "id": "23pSS-eH0Nd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def guardarPesos(nombreCarpeta = None):\n",
        "  if(nombreCarpeta == None):\n",
        "    now = datetime.now()\n",
        "    partes = str(now).split(' ')\n",
        "    nombreCarpeta = partes[0] + \"_\" + partes[1].split('.')[0]\n",
        "\n",
        "  if(not os.path.exists(\"mydrive/ProyectoFinal/Weight/\" + nombreCarpeta)):\n",
        "    os.mkdir(\"mydrive/ProyectoFinal/Weight/\" + nombreCarpeta)\n",
        "\n",
        "  for filename in os.listdir(\"mydrive/ProyectoFinal/Weight\"):\n",
        "    if filename.endswith(\".weights\") and not filename.endswith(\"last.weights\"):\n",
        "      shutil.move(\"mydrive/ProyectoFinal/Weight/\" + filename, \"mydrive/ProyectoFinal/Weight/\" + nombreCarpeta)\n",
        "\n",
        "\n",
        "def realizarFineTuning(archivoData, archivoModelo, archivoPesos):\n",
        "  os.system(\"./darknet detector train \" + archivoData + \" \" + archivoModelo + \" \" + archivoPesos + \" -dont_show\")\n"
      ],
      "metadata": {
        "id": "Q-bnZ11O0VaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para evaluación del modelo**"
      ],
      "metadata": {
        "id": "8DQbf-K33ORb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def realizarEvaluacion(archivoData, archivoModelo, archivoPesos, archivoSalida):\n",
        "  archivoModeloTest = generarModeloTest(archivoModelo)\n",
        "\n",
        "  os.system(r\"./darknet detector recprec \" + archivoData + \" \" + archivoModeloTest + \" \" + archivoPesos + \" > \" + archivoSalida)\n"
      ],
      "metadata": {
        "id": "i93hBTc63RSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para detección videos**"
      ],
      "metadata": {
        "id": "L53-3ZOe0MNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *\n",
        "\n",
        "def realizarDeteccionVideo(archivoVideo, archivoData, archivoModelo, archivoPesos, archivoSalida, start = None, end = None):\n",
        "  archivoModeloTest = generarModeloTest(archivoModelo)\n",
        "  #booleano con el que indicamos si se modifica o no el video indicado\n",
        "  modificado = False\n",
        "  #cargamos el archivo del video\n",
        "  video = VideoFileClip(archivoVideo)\n",
        "  #vemos si el video es horizontal o vertical, si es horizontal lo rotamos para ponerlo en vertical\n",
        "  if video.size[0] > video.size[1]:\n",
        "    video = video.rotate(90)\n",
        "    modificado = True\n",
        "\n",
        "  #si se indica el inicio se recorta el video dejando el fragmento comprendido entre start y end\n",
        "  if start != None:\n",
        "    video = video.subclip(start,end)\n",
        "    modificado = True\n",
        "\n",
        "  #creamos el nombre del video editado\n",
        "  nombre = archivoVideo.split(\".\")[0]\n",
        "  if start != None:\n",
        "    nombreFinal = nombre + \"_modificado_\"+str(start)+\"_\"+ str(end)+\".mp4\"\n",
        "  else:\n",
        "    nombreFinal = nombre + \"_modificado_entero.mp4\"\n",
        "\n",
        "  if modificado:\n",
        "    video.write_videofile(nombreFinal)\n",
        "  else:\n",
        "    #si no se modifica el archivo entonces le pasamos como argumento a la función darknet el video original\n",
        "    nombreFinal = archivoVideo\n",
        "\n",
        "  os.system(\"./darknet detector demo \" + archivoData + \" \" + archivoModeloTest + \" \" + archivoPesos + \" -dont_show \" + nombreFinal + \" -i 0 -out_filename results.avi\")\n",
        "\n",
        "  os.system(\"mv results.avi \" + archivoSalida)\n"
      ],
      "metadata": {
        "id": "J2LsJJ6B0VxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Funciones para visualización de videos**"
      ],
      "metadata": {
        "id": "MG_T4ztPosuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def show_video(video_ori, video_detec, video_width = 600):   \n",
        "  codigo_HTML = \"\"\"<table border=\"1\">\n",
        "                      <tr>\n",
        "                          <th>Video Original</th>\n",
        "                          <th>Video con Detecciones</th>\n",
        "                      </tr>\n",
        "                      <tr>\"\"\"\n",
        "  \n",
        "  for video in [video_ori, video_detec]:\n",
        "    formatoVideo = video.split('.')[1]\n",
        "    rutaVideo = video.split('.')[0]\n",
        "\n",
        "    if(formatoVideo == \"avi\"):\n",
        "      os.system(\"ffmpeg -i \" + video + \" \" + rutaVideo + \".mp4\")\n",
        "      video = rutaVideo + \".mp4\"\n",
        "    \n",
        "    video_file = open(video, \"r+b\").read()\n",
        "  \n",
        "    video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "\n",
        "    if(formatoVideo == \"avi\"):\n",
        "      os.system(\"rm \" + video)\n",
        "\n",
        "    codigo_HTML += f\"\"\"<td><video width={video_width} controls><source src=\"{video_url}\"></video></td>\"\"\"\n",
        "\n",
        "  codigo_HTML += \"</tr></table>\"\n",
        "\n",
        "  return HTML(codigo_HTML)\n"
      ],
      "metadata": {
        "id": "TYIUpkYjov4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Generación entorno de trabajo**</u>"
      ],
      "metadata": {
        "id": "RkT-QFlogYvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Clonar y Construir Darknet**"
      ],
      "metadata": {
        "id": "RycGCZpu_vDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Clonar repositorio del proyecto final\n",
        "!git clone https://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@github.com/Mario-Carmona/ProyectoFinal-VC.git\n",
        "%cd ProyectoFinal-VC"
      ],
      "metadata": {
        "id": "Q00XO8fg9aVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mover contenido de la darknet\n",
        "!mv darknet/* ./\n",
        "# Eliminar la carpeta que contenía a la darknet\n",
        "!rm -rf darknet\n"
      ],
      "metadata": {
        "id": "wFC_u-0_b7Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cambiar makefile para tener activados la GPU y OpenCV\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n"
      ],
      "metadata": {
        "id": "3-tEGaW8_53d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "metadata": {
        "id": "A-amC-W5ALrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contruir Darknet (Al contruir Darknet se podrá usar los archivos ejecutable \n",
        "# para ejecutar o entrenar el reconocimiento de objetos)\n",
        "\n",
        "!make\n"
      ],
      "metadata": {
        "id": "sPnyUomxAYou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generar carpetas en Drive**"
      ],
      "metadata": {
        "id": "1dX43KP1fnWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/ ./mydrive\n"
      ],
      "metadata": {
        "id": "GqMpxJqnhITb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generarDirectorioPrin(r'mydrive/ProyectoFinal')\n"
      ],
      "metadata": {
        "id": "xLZOlZg3hMhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generar Dataset**"
      ],
      "metadata": {
        "id": "VZuF9Zu1kEo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generarDataset(\"BBDD_Nadadores/TrainingSET/\", \"data/\", 0.2)\n"
      ],
      "metadata": {
        "id": "so6VTYl4kHLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Descargar pesos preentrenados YOLOv3**"
      ],
      "metadata": {
        "id": "pA8PuT9GOHwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov3.weights\n"
      ],
      "metadata": {
        "id": "R0nFdV1ZOMR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://pjreddie.com/media/files/darknet53.conv.74\n"
      ],
      "metadata": {
        "id": "XQDuQDDnkrn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n"
      ],
      "metadata": {
        "id": "HT1T0_cwtoSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Modelo Base YOLOv3**</u>"
      ],
      "metadata": {
        "id": "1S1pSVs7ZRTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar Fine Tuning**"
      ],
      "metadata": {
        "id": "2iUVnjzOchho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-modeloBase.cfg\"\n",
        "archivoPesos = \"darknet53.conv.74\"\n",
        "\n",
        "realizarFineTuning(archivoData, archivoModelo, archivoPesos)\n",
        "\"\"\"\n",
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov3-modeloBase.cfg darknet53.conv.74 -dont_show\n"
      ],
      "metadata": {
        "id": "4Xe9J8jxcTut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "guardarPesos(\"ModeloBaseYOLOv3\")\n"
      ],
      "metadata": {
        "id": "URe0DUVMdzRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generar gráficas**"
      ],
      "metadata": {
        "id": "lqlnpMgbc-qw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar detecciones en videos**"
      ],
      "metadata": {
        "id": "rVCELLIffteF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-modeloBase.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/ModeloBaseYOLOv3/yolov3-modeloBase_2000.weights\"\n",
        "archivoVideo = \"mydrive/ProyectoFinal/Videos/video1_rotate_recortado.mp4\"\n",
        "archivoSalida = \"mydrive/ProyectoFinal/results10.avi\"\n",
        "\n",
        "realizarDeteccionVideo(archivoVideo, archivoData, archivoModelo, archivoPesos, archivoSalida)\n"
      ],
      "metadata": {
        "id": "dumpB3MMfteG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualización videos**"
      ],
      "metadata": {
        "id": "IkyFmBaOgR5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "video_ori = \"mydrive/ProyectoFinal/Videos/video1_rotate_recortado.mp4\"\n",
        "video_detec = \"mydrive/ProyectoFinal/results7.avi\"\n",
        "show_video(video_ori, video_detec, 400)\n"
      ],
      "metadata": {
        "id": "W60Q0zmvgR5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Modelo Mejorado YOLOv3**</u>"
      ],
      "metadata": {
        "id": "6gmjrMwOZisO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar Fine Tuning**"
      ],
      "metadata": {
        "id": "q3wZ0LebjbsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-fineTuning.cfg\"\n",
        "archivoPesos = \"darknet53.conv.74\"\n",
        "\n",
        "realizarFineTuning(archivoData, archivoModelo, archivoPesos)\n",
        "\"\"\"\n",
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov3-fineTuning.cfg darknet53.conv.74 -dont_show\n"
      ],
      "metadata": {
        "id": "GE40D4DwoXmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "guardarPesos(\"FineTuningYOLOv3\")\n"
      ],
      "metadata": {
        "id": "24fitjSEoXmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generar gráficas**"
      ],
      "metadata": {
        "id": "sLcSIWhOgrI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar detecciones en videos**"
      ],
      "metadata": {
        "id": "PglEgdMfljnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-fineTuningAmpli.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/FineTuningYOLOv3/yolov3-fineTuning_2000.weights\"\n",
        "archivoVideo = \"mydrive/ProyectoFinal/Videos/video1_rotate_recortado.mp4\"\n",
        "archivoSalida = \"mydrive/ProyectoFinal/results10.avi\"\n",
        "\n",
        "realizarDeteccionVideo(archivoVideo, archivoData, archivoModelo, archivoPesos, archivoSalida)\n"
      ],
      "metadata": {
        "id": "LE9ccqZmloxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualización videos**"
      ],
      "metadata": {
        "id": "DhUgyfPDof9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "video_ori = \"mydrive/ProyectoFinal/Videos/video1_rotate_recortado.mp4\"\n",
        "video_detec = \"mydrive/ProyectoFinal/results7.avi\"\n",
        "show_video(video_ori, video_detec, 400)\n"
      ],
      "metadata": {
        "id": "htMIJeQKoiqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar detecciones con Modelo Fine Tuning**"
      ],
      "metadata": {
        "id": "s-AUA1tPjWvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "archivoImagen = \"mydrive/ProyectoFinal/imagen_video.jpg\"\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-fineTuningAmpli.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/2022-01-06_11\\:00\\:10/yolov3-video_3_1350.weights\"\n",
        "umbralDetec = 0.25\n",
        "\n",
        "realizarDeteccionImagen(archivoImagen, archivoData, archivoModelo, archivoPesos, umbralDetec)\n"
      ],
      "metadata": {
        "id": "mR7apI3e8PFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show image using our helper function\n",
        "imShow('imagen_video.jpg')"
      ],
      "metadata": {
        "id": "KRNqJ-yh8PFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "archivoImagen = \"mydrive/ProyectoFinal/imagen_video_flip.jpg\"\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-fineTuningAmpli.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/2022-01-06_11\\:00\\:10/yolov3-video_3_1350.weights\"\n",
        "umbralDetec = 0.25\n",
        "\n",
        "realizarDeteccionImagen(archivoImagen, archivoData, archivoModelo, archivoPesos, umbralDetec)\n"
      ],
      "metadata": {
        "id": "xIt3_Bhq8PFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# show image using our helper function\n",
        "imShow('imagen_video_flip.jpg')\n"
      ],
      "metadata": {
        "id": "AOY-K-bB8PFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "carpetaImagenes = \"BBDD_Nadadores/crops_120x120\"\n",
        "archivoData = \"cfg/obj.data\"\n",
        "archivoModelo = \"cfg/yolov3-fineTuningAmpli.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/2022-01-06_11\\:00\\:10/yolov3-video_3_1350.weights\"\n",
        "archivoJSON = \"modeloFineTuning.json\"\n",
        "umbralDetec = 0.25\n",
        "carpetaDrive = \"mydrive/ProyectoFinal/ModeloFineTuning\"\n",
        "umbralPredic = 0.3\n",
        "\n",
        "realizarDeteccionImagenes(carpetaImagenes, archivoData, archivoModelo, archivoPesos, archivoJSON, umbralDetec, carpetaDrive, umbralPredic)\n"
      ],
      "metadata": {
        "id": "MFkCZ_Lx8PFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Modelo Mejorado YOLOv4**</u>"
      ],
      "metadata": {
        "id": "Gmz3vFjZi1pA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar Fine Tuning**"
      ],
      "metadata": {
        "id": "c1p52rm5k1p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov4-fineTuning.cfg\"\n",
        "archivoPesos = \"yolov4.conv.137\"\n",
        "\n",
        "realizarFineTuning(archivoData, archivoModelo, archivoPesos)\n",
        "\"\"\"\n",
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov4-fineTuning.cfg yolov4.conv.137 -dont_show\n"
      ],
      "metadata": {
        "id": "BTf6EqfLk1p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "guardarPesos(\"FineTuningYOLOv4\")\n"
      ],
      "metadata": {
        "id": "jHC2AAmRk1p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generar gráficas**"
      ],
      "metadata": {
        "id": "E-hwq5yTnCP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ejecutar detecciones en videos**"
      ],
      "metadata": {
        "id": "JTWDdstDn6ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov4-fineTuningAmpli.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/FineTuningYOLOv4/yolov4-fineTuning_2000.weights\"\n",
        "archivoVideo = \"mydrive/ProyectoFinal/Videos/video1_rotate_recortado.mp4\"\n",
        "archivoSalida = \"mydrive/ProyectoFinal/results10.avi\"\n",
        "\n",
        "realizarDeteccionVideo(archivoVideo, archivoData, archivoModelo, archivoPesos, archivoSalida)\n"
      ],
      "metadata": {
        "id": "TcSv0m6Nn6ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualización videos**"
      ],
      "metadata": {
        "id": "CqaSmY0Cn6ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "video_ori = \"mydrive/ProyectoFinal/Videos/video1_rotate_recortado.mp4\"\n",
        "video_detec = \"mydrive/ProyectoFinal/results7.avi\"\n",
        "show_video(video_ori, video_detec, 400)\n"
      ],
      "metadata": {
        "id": "MMU2SwJOn6ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Generación gráficas**</u>"
      ],
      "metadata": {
        "id": "-Zwo45r7wwO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluacionModelo(pesosv3Base,modelov3Base,\"Datosv3Base.txt\",400,2050)"
      ],
      "metadata": {
        "id": "HNF03fZuw6nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostrarGrafica(\"F1-score\",\"Datosv3.txt\",400,2050)\n",
        "#mostrarGrafica(\"avg-iou\",\"Datosv3.txt\",400,2050)\n",
        "#mostrarGrafica(\"F1-score\",\"Datosv4.txt\",400,2050)\n",
        "#mostrarGrafica(\"avg-iou\",\"Datosv4.txt\",400,2050)"
      ],
      "metadata": {
        "id": "aLp7wzQy3l3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostrarGrafica(\"precision\")\n",
        "#mostrarGrafica(\"recall\")\n",
        "#mostrarGrafica(\"F1-score\")"
      ],
      "metadata": {
        "id": "n_Xr95GE8-zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Ejecutar Fine Tuning YOLOv4**</u>"
      ],
      "metadata": {
        "id": "T-OiqvRz6SvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov4-fineTuning.cfg yolov4.conv.137 -dont_show\n"
      ],
      "metadata": {
        "id": "R1YN5hnf6YOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "guardarPesos(\"FineTuningYOLOv4\")\n"
      ],
      "metadata": {
        "id": "PQ75a8Ea3p5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Ejecutar evaluación del Modelo Fine Tuning YOLOv4**</u>"
      ],
      "metadata": {
        "id": "B9Gmixhf6tzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov4-fineTuning.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/yolov4-prueba_3_1700.weights\"\n",
        "archivoSalida = \"mydrive/ProyectoFinal/DatosGrafica/datos16.txt\"\n",
        "\n",
        "realizarEvaluacion(archivoData, archivoModelo, archivoPesos, archivoSalida)"
      ],
      "metadata": {
        "id": "7NC-SECebYjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <u>**Ejecutar detecciones en Test con Mejor Modelo**</u>"
      ],
      "metadata": {
        "id": "uowo4PRchPfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "carpetaImagenes = \"BBDD_Nadadores/crops_120x120\"\n",
        "archivoData = \"cfg/obj.data\"\n",
        "archivoModelo = \"cfg/yolov4-fineTuning.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/FineTuningYOLOv4/yolov4-fineTuning_2000.weights\"\n",
        "archivoJSON = \"mejorModelo.json\"\n",
        "umbralDetec = 0.25\n",
        "carpetaDrive = \"mydrive/ProyectoFinal/MejorModelo\"\n",
        "umbralPredic = 0.3\n",
        "\n",
        "realizarDeteccionImagenes(carpetaImagenes, archivoData, archivoModelo, archivoPesos, archivoJSON, umbralDetec, carpetaDrive, umbralPredic)\n"
      ],
      "metadata": {
        "id": "nbnApLK2lYBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Detección en videos**"
      ],
      "metadata": {
        "id": "a_mHaVfAPQ39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "archivoData = \"data/obj.data\"\n",
        "archivoModelo = \"cfg/yolov4-fineTuningAmpli.cfg\"\n",
        "archivoPesos = \"mydrive/ProyectoFinal/Weight/FineTuningYOLOv4/yolov4-prueba_3_1850.weights\"\n",
        "archivoVideo = \"mydrive/ProyectoFinal/Videos/video3_modificado_21_28.mp4\"\n",
        "archivoSalida = \"mydrive/ProyectoFinal/results_resultadov4_vuelta.avi\"\n",
        "\n",
        "realizarDeteccionVideo(archivoVideo, archivoData, archivoModelo, archivoPesos, archivoSalida)"
      ],
      "metadata": {
        "id": "kYwovBWqPQP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls mydrive/ProyectoFinal"
      ],
      "metadata": {
        "id": "kBP9WSV1RIRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba parametros darknet"
      ],
      "metadata": {
        "id": "aRjfoU0eejJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Threshold Flag"
      ],
      "metadata": {
        "id": "ua_6ddtEeoCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is ran without the threshold flag set\n",
        "#!./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg\n",
        "#imShow('predictions.jpg')"
      ],
      "metadata": {
        "id": "2GdI4s3gej62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same detections but ran with the threshold flag set to 0.5 (pottedplant is no longer detected!)\n",
        "#!./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg -thresh 0.5\n",
        "#imShow('predictions.jpg')"
      ],
      "metadata": {
        "id": "QoYVSsLBemkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output Bounding Box Coordinates"
      ],
      "metadata": {
        "id": "T5bSGeSde9_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# darknet run with external output flag to print bounding box coordinates\n",
        "#!./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/person.jpg -ext_output\n",
        "#imShow('predictions.jpg')"
      ],
      "metadata": {
        "id": "unJQjKLmezmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Don't Show Image"
      ],
      "metadata": {
        "id": "FSkAXvCGfVY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!./darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/person.jpg -dont_show\n",
        "#imShow('predictions.jpg')"
      ],
      "metadata": {
        "id": "evec6df_fQrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}